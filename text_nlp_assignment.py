# -*- coding: utf-8 -*-
"""Text NLP Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTppkvNkXq8fvQDC8QWv10l1Rbzv02XI

Importing Necessary Libraries
"""

!pip install openpyxl

!pip install transformers

!pip install vaderSentiment

!pip install textblob

!pip install textatistic

import csv
import pandas as pd
from bs4 import BeautifulSoup
import requests
import re
import transformers

df = pd.read_excel('/content/Input.xlsx')

df.head()

df.shape

df.iloc[63,1]

link = df.iloc[63,1]

headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',
}

source = requests.get(link, headers=headers).text
data = BeautifulSoup(source, 'lxml')
article = data.find('article')
title = article.h1.text
body =  article.find('div', class_='td-post-content').text
date = article.find('div', class_='td-module-meta-info').time.text

title

body

footer = article.find('div', class_='td-post-content').pre.text 
footer

body = body.replace(footer, '')

body

new_body = body.replace('\n',' ')
new_body = new_body.replace('\xa0',' ')

new_body

date

new_body = [i for i in new_body if i is not None]

titles=[]
bodies=[]
csv_file = open('blackcoffer.csv', 'w')
csv_writer = csv.writer(csv_file)
csv_writer.writerow(['Id', 'Date', 'Title', 'Text'])
for index in range(0, df.shape[0], 1):
  source = requests.get(df.iloc[index,1],headers=headers).text
  data = BeautifulSoup(source, 'lxml')
  art = data.find('article')
  title = art.h1.text
  titles.append(title)
  body = art.find('div',class_='td-post-content').text
  body = body.replace('\n',' ')
  body = body.replace('\xa0',' ')
  date = art.find('div', class_='td-module-meta-info').time.text
  try:
    footer = art.find('div',class_='td-post-content').pre.text
    body = body.replace(footer,'')
  except Exception as x:
    footer=''
  bodies.append(body)
  csv_writer.writerow([df.iloc[index,0], date, title, body])
csv_file.close()

file = pd.read_csv('./blackcoffer.csv')

file.shape

file.head()

from textblob import TextBlob

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
sentiment = SentimentIntensityAnalyzer()

from textatistic import Textatistic

#function to calculate the average sentence length across a piece of text.
def avg_sentence_len(text):
  sentences = text.split(".") #split the text into a list of sentences.
  words = text.split(" ") #split the input text into a list of separate words
  if(sentences[len(sentences)-1]==""): #if the last value in sentences is an empty string
    average_sentence_length = len(words) / len(sentences)-1
  else:
    average_sentence_length = len(words) / len(sentences)
  return average_sentence_length #returning avg length of sentence

"""Positive, Negative and Neutral Scores"""

for index in range(0, file['Text'].shape[0], 1):
  sentimentAnalysis = sentiment.polarity_scores(file['Text'][index])
  print(sentimentAnalysis)

"""Polarity"""

for index in range(0, file['Text'].shape[0], 1):
  polar = TextBlob(file['Text'][index])
  print(polar.sentiment.polarity)

"""Textatistic is a Python package to calculate the Flesch Reading Ease, Flesch-Kincaid, Gunning Fog, Simple Measure of Gobbledygook (SMOG) and Dale-Chall readability indices. Textatistic also contains functions to count the number of sentences, characters, syllables, words, words with three or more syllables and words on an expanded Dale-Chall list of easy words."""

for index in range(0, file['Text'].shape[0], 1):

  sent1 =Textatistic(file['Text'][index])

  print(sent1.counts, sent1.scores)

"""Average sentence length"""

#**
a_file = open('asl.csv', 'w')
a_writer = csv.writer(a_file)
a_writer.writerow(['Id', 'ASL'])
#**
for index in range(0, file['Text'].shape[0], 1):
  asl = avg_sentence_len(file['Text'][index])
  print(asl) #printing result
  #**
  a_writer.writerow([df.iloc[index,0], asl])
a_file.close()

#**